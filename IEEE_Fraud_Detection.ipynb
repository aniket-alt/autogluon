{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXhY/IUvUzaZRWjxnD5XQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniket-alt/autogluon/blob/main/IEEE_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use AutoGluon for Kaggle competitions\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "This tutorial will teach you how to use AutoGluon to become a serious Kaggle competitor without writing lots of code.\n",
        "We first outline the general steps to use AutoGluon in Kaggle contests. Here, we assume the competition involves tabular data which are stored in one (or more) CSV files.\n",
        "\n",
        "1) Run Bash command: pip install kaggle\n",
        "\n",
        "2) Navigate to: https://www.kaggle.com/account and create an account (if necessary).\n",
        "Then , click on \"Create New API Token\" and move downloaded file to this location on your machine: `~/.kaggle/kaggle.json`. For troubleshooting, see [Kaggle API instructions](https://www.kaggle.com/docs/api).\n",
        "\n",
        "3) To download data programmatically: Execute this Bash command in your terminal:\n",
        "\n",
        "`kaggle competitions download -c [COMPETITION]`\n",
        "\n",
        "Here, [COMPETITION] should be replaced by the name of the competition you wish to enter.\n",
        "Alternatively, you can download data manually: Just navigate to website of the Kaggle competition you wish to enter, click \"Download All\", and accept the competition's terms.\n",
        "\n",
        "4) If the competition's training data is comprised of multiple CSV files, use [pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to properly merge/join them into a single data table where rows = training examples, columns = features.\n",
        "\n",
        "5) Run autogluon `fit()` on the resulting data table.\n",
        "\n",
        "6) Load the test dataset from competition (again making the necessary merges/joins to ensure it is in the exact same format as the training data table), and then call autogluon `predict()`.  Subsequently use [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to load the competition's `sample_submission.csv` file into a DataFrame, put the AutoGluon predictions in the right column of this DataFrame, and finally save it as a CSV file via [pandas.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html). If the competition does not offer a sample submission file, you will need to create the submission file yourself by appropriately reformatting AutoGluon's test predictions.\n",
        "\n",
        "7) Submit your predictions via Bash command:\n",
        "\n",
        "`kaggle competitions submit -c [COMPETITION] -f [FILE] -m [\"MESSAGE\"]`\n",
        "\n",
        "Here, [COMPETITION] again is the competition's name, [FILE] is the name of the CSV file you created with your predictions, and [\"MESSAGE\"] is a string message you want to record with this submitted entry. Alternatively, you can  manually upload your file of predictions on the competition website.\n",
        "\n",
        "8) Finally, navigate to competition leaderboard website to see how well your submission performed!\n",
        "It may take time for your submission to appear.\n",
        "\n",
        "\n",
        "\n",
        "Below, we demonstrate how to do steps (4)-(6) in Python for a specific Kaggle competition: [ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\n",
        "This means you'll need to run the above steps with `[COMPETITION]` replaced by `ieee-fraud-detection` in each command.  Here, we assume you've already completed steps (1)-(3) and the data CSV files are available on your computer. To begin step (4), we first load the competition's training data into Python:"
      ],
      "metadata": {
        "id": "gVNS4eS1U8NW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Kaggle Key and Username as Secrets, Download Dataset and unzip it"
      ],
      "metadata": {
        "id": "5PH1h2KyVLMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7OVZUesUTli",
        "outputId": "406e34a7-45ad-4255-a11a-3d3b2f8cd73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content\n",
            "\r  0% 0.00/118M [00:00<?, ?B/s]\n",
            "\r100% 118M/118M [00:00<00:00, 1.67GB/s]\n",
            "Archive:  /content/ieee-fraud-detection.zip\n",
            "  inflating: /content/ieee-fraud-detection/sample_submission.csv  \n",
            "  inflating: /content/ieee-fraud-detection/test_identity.csv  \n",
            "  inflating: /content/ieee-fraud-detection/test_transaction.csv  \n",
            "  inflating: /content/ieee-fraud-detection/train_identity.csv  \n",
            "  inflating: /content/ieee-fraud-detection/train_transaction.csv  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "\n",
        "!unzip /content/ieee-fraud-detection.zip -d /content/ieee-fraud-detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pip\n",
        "!pip3 install -U setuptools wheel\n",
        "\n",
        "!pip3 install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S9V_X5EEWGDf",
        "outputId": "b0d49652-b57c-4c83-d639-9169009011ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "67b164370f804b179b821ab381e392ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.4.0 (from autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.core-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.4.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.tabular-1.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting autogluon.multimodal==1.4.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.4.0 (from autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.timeseries-1.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading boto3-1.40.66-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting autogluon.common==1.4.0 (from autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading autogluon.common-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyarrow<21.0.0,>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (18.1.0)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.5.2)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.4.0->autogluon) (0.2.7)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (11.3.0)\n",
            "Collecting torch<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting lightning<2.8,>=2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.11.0)\n",
            "Requirement already satisfied: fsspec<=2025.3 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2025.3.0)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting torchvision<0.23.0,>=0.16.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.9.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.4.0->autogluon) (2.19.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (2.8.5)\n",
            "Collecting loguru (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (4.6.0)\n",
            "Collecting einx (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting xgboost<3.1,>=2.0 (from autogluon.tabular[all]==1.4.0->autogluon)\n",
            "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (3.8.7)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.4.0->autogluon) (0.36.0)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading fugue-0.9.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon) (0.6.2)\n",
            "Collecting botocore<1.41.0,>=1.40.66 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading botocore-1.40.66-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.66->boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.66->boto3<2,>=1.10->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.4.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (25.3)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.9,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.8.13)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (2.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (3.13.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.11.10)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (4.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.4.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.4.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.4.0->autogluon) (0.28.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (80.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.2.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.4.0->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.4.0->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (3.20.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.8.0)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.76.0)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (7.4.1)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (2025.10.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.4.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.20.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.14.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.4.0->autogluon) (3.1.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.5.4.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[torch]->autogluon.tabular[all]==1.4.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.4.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (0.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.4.0->autogluon) (1.22.0)\n",
            "Collecting triad>=1.0.0 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading triad-1.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting adagio>=0.2.6 (from fugue>=0.9.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.4.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (0.43.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8,>=2.2->autogluon.multimodal==1.4.0->autogluon) (1.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (2.8)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx->autogluon.tabular[all]==1.4.0->autogluon) (2.4.6)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.28.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.71.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon) (0.6.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging>=20.0 (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.4.0->autogluon.core[all]==1.4.0->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.4.0->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.17.0)\n",
            "Collecting colorlog (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (2.0.44)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (1.3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.4.0->autogluon.timeseries[all]==1.4.0->autogluon) (3.2.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.4.0->autogluon) (8.5.0)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.4.0->autogluon) (0.22.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.4.0->autogluon) (1.7.1)\n",
            "Downloading autogluon-1.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading autogluon.core-1.4.0-py3-none-any.whl (225 kB)\n",
            "Downloading autogluon.common-1.4.0-py3-none-any.whl (70 kB)\n",
            "Downloading autogluon.features-1.4.0-py3-none-any.whl (64 kB)\n",
            "Downloading autogluon.multimodal-1.4.0-py3-none-any.whl (454 kB)\n",
            "Downloading autogluon.tabular-1.4.0-py3-none-any.whl (487 kB)\n",
            "Downloading autogluon.timeseries-1.4.0-py3-none-any.whl (189 kB)\n",
            "Downloading boto3-1.40.66-py3-none-any.whl (139 kB)\n",
            "Downloading botocore-1.40.66-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Downloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\n",
            "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "Downloading ray-2.44.1-cp312-cp312-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m149.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m164.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m172.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\n",
            "Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.2-py3-none-any.whl (280 kB)\n",
            "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "Downloading triad-1.0.0-py3-none-any.whl (59 kB)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m162.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\n",
            "Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19208 sha256=0ee4d20a602a792eac744fdecda895cbe3df09e37e20a332f8b68989167b9cc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/65/79/33dee66cba26e8204801916dfee7481bccfd22905ebb841fe5\n",
            "  Building wheel for seqeval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16250 sha256=e11c0857ddebe12b80f51bf237005546983fda5593496027c024e46e35e178be\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, nvidia-cusparselt-cu12, distlib, colorful, virtualenv, triton, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, nvidia-nccl-cu12, nvidia-cudnn-cu12, loguru, lightning-utilities, jmespath, coreforecast, colorlog, colorama, xgboost, window-ops, model-index, einx, botocore, utilsforecast, triad, torch, tokenizers, seqeval, s3transfer, optuna, opendatalab, jsonschema, gluonts, catboost, aiohttp_cors, transformers, torchvision, torchmetrics, ray, pytorch-metric-learning, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, timm, pytorch-lightning, fugue, evaluate, autogluon.common, statsforecast, lightning, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.4.0\n",
            "\u001b[2K    Uninstalling triton-3.4.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.4.0\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[2K  Attempting uninstall: xgboost\n",
            "\u001b[2K    Found existing installation: xgboost 3.1.1\n",
            "\u001b[2K    Uninstalling xgboost-3.1.1:\n",
            "\u001b[2K      Successfully uninstalled xgboost-3.1.1\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.8.0+cu126\n",
            "\u001b[2K    Uninstalling torch-2.8.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torch-2.8.0+cu126\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
            "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[2K  Attempting uninstall: jsonschema\n",
            "\u001b[2K    Found existing installation: jsonschema 4.25.1\n",
            "\u001b[2K    Uninstalling jsonschema-4.25.1:\n",
            "\u001b[2K      Successfully uninstalled jsonschema-4.25.1\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.57.1\n",
            "\u001b[2K    Uninstalling transformers-4.57.1:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.57.1\n",
            "\u001b[2K  Attempting uninstall: torchvision\n",
            "\u001b[2K    Found existing installation: torchvision 0.23.0+cu126\n",
            "\u001b[2K    Uninstalling torchvision-0.23.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[2K  Attempting uninstall: timm\n",
            "\u001b[2K    Found existing installation: timm 1.0.21\n",
            "\u001b[2K    Uninstalling timm-1.0.21:\n",
            "\u001b[2K      Successfully uninstalled timm-1.0.21\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63/63\u001b[0m [autogluon]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 autogluon-1.4.0 autogluon.common-1.4.0 autogluon.core-1.4.0 autogluon.features-1.4.0 autogluon.multimodal-1.4.0 autogluon.tabular-1.4.0 autogluon.timeseries-1.4.0 boto3-1.40.66 botocore-1.40.66 catboost-1.2.8 colorama-0.4.6 colorful-0.5.8 colorlog-6.10.1 coreforecast-0.0.16 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fugue-0.9.2 gluonts-0.16.2 jmespath-1.0.1 jsonschema-4.23.0 lightning-2.5.5 lightning-utilities-0.15.2 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 nlpaug-1.1.11 nvidia-cudnn-cu12-9.5.1.17 nvidia-cusparselt-cu12-0.6.3 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.26.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.5.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.1 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.5 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.14.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.4 timm-1.0.3 tokenizers-0.21.4 torch-2.7.1 torchmetrics-1.7.4 torchvision-0.22.1 transformers-4.49.0 triad-1.0.0 triton-3.3.1 utilsforecast-0.2.11 virtualenv-20.35.4 window-ops-0.0.15 xgboost-3.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = './ieee-fraud-detection/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "OxQNXOYGWTyU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the training data for this competition is comprised of multiple CSV files, we just first join them into a single large table (with rows = examples, columns = features) before applying AutoGluon:"
      ],
      "metadata": {
        "id": "ppDTe-XKWj72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "ZwwkZJLxWmyv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that a left-join on the TransactionID key happened to be most appropriate for this Kaggle competition, but for others involving multiple training data files, you will likely need to use a different join strategy (always consider this very carefully). Now that all our training data resides within a single table, we can apply AutoGluon. Below, we specify the presets argument to maximize AutoGluon's predictive accuracy which usually requires that you run fit() with longer time limits (3600s below should likely be increased in your run):"
      ],
      "metadata": {
        "id": "Pa8nqx05Womj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=300)\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "id": "licvdqOuWqSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d71cc6-79e1-4b19-e783-cc06fc5b8b75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          12\n",
            "GPU Count:          1\n",
            "Memory Avail:       45.91 GB / 52.96 GB (86.7%)\n",
            "Disk Space Avail:   188.71 GB / 235.68 GB (80.1%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True, 'num_bag_sets': 1}\n",
            "Full kwargs:\n",
            "{'_experimental_dynamic_hyperparameters': False,\n",
            " '_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_model_failure': False,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-11-05 00:58:53,109\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Beginning AutoGluon training ... Time limit = 72s\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m AutoGluon will save models to \"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Train Data Rows:    524924\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Train Data Columns: 433\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Label Column:       isFraud\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tAvailable Memory:                    42332.80 MB\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTrain Data (Original)  Memory Usage: 2231.12 MB (5.3% of available memory)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tWarning: Data size prior to feature transformation consumes 5.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t5.9s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t4.4s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t0.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t1.2s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t4.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t3 duplicate columns removed: ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t4.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t\t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tUnused Original Features (Count: 3): ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('float', []) : 3 | ['V28', 'V154', 'V241']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('float64', 'float') : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('float', [])  : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('float64', 'float')     : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('float', [])    : 396 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t30.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t430 features in original data used to generate 430 features in processed data.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTrain Data (Processed) Memory Usage: 1614.47 MB (3.8% of available memory)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Data preprocessing and feature engineering runtime = 35.71s ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 23.99s of the 35.99s of remaining time.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 12\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 26.43% memory usage per fold, 52.86%/80.00% total).\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=26.43%)\n",
            "\u001b[36m(_ray_fit pid=3752)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=3753)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=3753)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.14124\n",
            "\u001b[36m(_ray_fit pid=3753)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=3752)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F1/model.pkl\n",
            "\u001b[36m(_ray_fit pid=3974)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=3752)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=3752)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.14146\n",
            "\u001b[36m(_ray_fit pid=3753)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F2/model.pkl\n",
            "\u001b[36m(_ray_fit pid=3974)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=3974)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141873\n",
            "\u001b[36m(_ray_fit pid=3975)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=3974)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F3/model.pkl\n",
            "\u001b[36m(_ray_fit pid=4178)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=3975)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=3975)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.140291\n",
            "\u001b[36m(_ray_fit pid=3975)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F4/model.pkl\n",
            "\u001b[36m(_ray_fit pid=4178)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4178)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141632\n",
            "\u001b[36m(_ray_fit pid=4179)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=4178)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F5/model.pkl\n",
            "\u001b[36m(_ray_fit pid=4387)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=4179)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4179)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141825\n",
            "\u001b[36m(_ray_fit pid=4179)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F6/model.pkl\n",
            "\u001b[36m(_ray_fit pid=4387)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4387)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141434\n",
            "\u001b[36m(_ray_fit pid=4388)\u001b[0m \tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_ray_fit pid=4387)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/S1F7/model.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t68.18s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.9s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t72649.8\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 36.00s of the -40.24s of remaining time.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m [1.]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.57s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.06s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.05s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t72103.1\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBMXT_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 36.00s of the -41.06s of remaining time.\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 12\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m [1.]\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.57s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.8002\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.06s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t0.06s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m \t72094.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m AutoGluon training complete, total runtime = 116.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 72103.1 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.4.0\"\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Loading: /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "\u001b[36m(_ray_fit pid=4388)\u001b[0m \tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=4388)\u001b[0m \t[1]\tvalid_set's binary_logloss: 0.141561\n",
            "\u001b[36m(_dystack pid=2722)\u001b[0m Saving /content/ieee-fraud-detection/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L1       0.832859   0.800213     roc_auc        3.154110       0.903182  68.177212                 3.154110                0.903182          68.177212            1       True          1\n",
            "1  WeightedEnsemble_L3       0.832859   0.800213     roc_auc        3.156323       0.958818  68.240576                 0.002213                0.055636           0.063365            3       True          3\n",
            "2  WeightedEnsemble_L2       0.832859   0.800213     roc_auc        3.157152       0.957967  68.240492                 0.003042                0.054785           0.063281            2       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t134s\t = DyStack   runtime |\t166s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 166s\n",
            "AutoGluon will save models to \"/content/ieee-fraud-detection/AutoGluonModels\"\n",
            "Train Data Rows:    590540\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    43396.51 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2531.61 MB (5.8% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 5.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t4.1s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t2.2s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.1s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.4s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t4 duplicate columns removed: ['V28', 'V154', 'V155', 'V156']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t429 features in original data used to generate 429 features in processed data.\n",
            "\tUnused Original Features (Count: 4): ['V28', 'V154', 'V155', 'V156']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 4 | ['V28', 'V154', 'V155', 'V156']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t24.8s = Fit runtime\n",
            "\t429 features in original data used to generate 429 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1811.77 MB (4.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 29.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}, {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "}\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/utils/data/y.pkl\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 91.45s of the 137.14s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.91% memory usage per fold, 57.82%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=28.91%)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.8765\t = Validation score   (roc_auc)\n",
            "\t85.32s\t = Training   runtime\n",
            "\t1.43s\t = Validation runtime\n",
            "\t51445.6\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 137.21s of the 43.17s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "\t0.99s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.8765\t = Validation score   (roc_auc)\n",
            "\t0.11s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "\t50931.9\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Gini', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'problem_types': ['binary', 'multiclass'], 'name_suffix': 'Entr', 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile'], 'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 42.90s of the 42.10s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.26% memory usage per fold, 60.52%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=6, gpus=0, memory=30.26%)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\t0.8418\t = Validation score   (roc_auc)\n",
            "\t68.67s\t = Training   runtime\n",
            "\t0.97s\t = Validation runtime\n",
            "\t30697.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'quantile', 'softclass'], 'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 137.21s of the -35.07s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 10\n",
            "Ensemble weights: \n",
            "[0.7 0.3]\n",
            "\t1.18s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.7, 'LightGBMXT_BAG_L2': 0.3}\n",
            "\t0.8765\t = Validation score   (roc_auc)\n",
            "\t5.54s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "\t30527.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 211.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 30527.1 rows/s (73818 batch size)\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/learner.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/predictor.pkl\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/version.txt with contents \"1.4.0\"\n",
            "Saving /content/ieee-fraud-detection/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/ieee-fraud-detection/AutoGluonModels\")\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3   0.876532     roc_auc       2.511848  159.529011                0.107124           5.540228            3       True          4\n",
            "1    LightGBMXT_BAG_L1   0.876506     roc_auc       1.434876   85.319031                1.434876          85.319031            1       True          1\n",
            "2  WeightedEnsemble_L2   0.876506     roc_auc       1.550637   85.433477                0.115761           0.114446            2       True          2\n",
            "3    LightGBMXT_BAG_L2   0.841786     roc_auc       2.404724  153.988783                0.969848          68.669752            2       True          3\n",
            "Number of models trained: 4\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/ieee-fraud-detection/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we use the trained AutoGluon Predictor to make predictions on the competition's test data. It is imperative that multiple test data files are joined together in the exact same manner as the training data. Because this competition is evaluated based on the AUC (Area under the ROC curve) metric, we ask AutoGluon for predicted class-probabilities rather than class predictions. In general, when to use predict vs predict_proba will depend on the particular competition."
      ],
      "metadata": {
        "id": "iHabrar1WrpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "# Reindex test_data to match the columns of train_data, filling missing columns with NaN\n",
        "test_data = test_data.reindex(columns=train_data.columns, fill_value=np.nan)\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities"
      ],
      "metadata": {
        "id": "_-xeGX6EW1Hr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "3ad18475-085e-4d36-f55f-d278610df531"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0  0.980020  0.019980\n",
              "1  0.976229  0.023771\n",
              "2  0.976859  0.023141\n",
              "3  0.981709  0.018291\n",
              "4  0.979448  0.020552"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11d4990b-2353-4516-bb4a-339f005d36d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.980020</td>\n",
              "      <td>0.019980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.976229</td>\n",
              "      <td>0.023771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.976859</td>\n",
              "      <td>0.023141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.981709</td>\n",
              "      <td>0.018291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.979448</td>\n",
              "      <td>0.020552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11d4990b-2353-4516-bb4a-339f005d36d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11d4990b-2353-4516-bb4a-339f005d36d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11d4990b-2353-4516-bb4a-339f005d36d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2e1e0d51-82df-45fb-8537-ac5092090963\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e1e0d51-82df-45fb-8537-ac5092090963')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2e1e0d51-82df-45fb-8537-ac5092090963 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_predproba"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in train_data:\")\n",
        "print(train_data.columns)\n",
        "\n",
        "print(\"\\nColumns in test_data after reindexing:\")\n",
        "print(test_data.columns)"
      ],
      "metadata": {
        "id": "FPtZQFiZW3GK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b562a4b-4319-4cd0-a2a6-9d74496fa7bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in train_data:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n",
            "\n",
            "Columns in test_data after reindexing:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When submitting predicted probabilities for classification competitions, it is imperative these correspond to the same class expected by Kaggle. For binary classification tasks, you can see which class AutoGluon's predicted probabilities correspond to via:"
      ],
      "metadata": {
        "id": "EFmkJsbkW1qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "id": "1faNBn6eW6pQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc21a897-1324-44b8-d631-83cd0cff74e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiclass classification tasks, you can see which classes AutoGluon's predicted probabilities correspond to via:"
      ],
      "metadata": {
        "id": "YJ-DbYp3W9YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "id": "lg45IDRIXApo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "accf0273-5373-4696-81f6-524f2cd3e9c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's get prediction probabilities for the entire test data, while only getting the positive class predictions by specifying:"
      ],
      "metadata": {
        "id": "x9bJAMehW9VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "id": "NkEIJ-jTXEhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb76117-e2cc-4f87-fc30-ddeabfe7ee4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/ieee-fraud-detection/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have made a prediction for each row in the test dataset, we can submit these predictions to Kaggle. Most Kaggle competitions provide a sample submission file, in which you can simply overwrite the sample predictions with your own as we do below:"
      ],
      "metadata": {
        "id": "q9ISh4udXFD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Nwm8MpOOXHgj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tips to maximize predictive performance:**\n",
        "\n",
        "*   Be sure to specify the appropriate evaluation metric if one is specified on the competition website! If you are unsure which metric is best, then simply do not specify this argument when invoking `fit()`; AutoGluon should still produce high-quality models by automatically inferring which metric to use.\n",
        "*   If the training examples are time-based and the competition test examples come from future data, we recommend you reserve the most recently-collected training examples as a separate validation dataset passed to `fit()`. Otherwise, you do not need to specify a validation set yourself and AutoGluon will automatically partition the competition training data into its own training/validation sets.\n",
        "* Beyond simply specifying `presets = 'best_quality'`, you may play with more advanced `fit()` arguments such as: `num_bag_folds`, `num_stack_levels`, `num_bag_sets`, `hyperparameter_tune_kwargs`, `hyperparameters`, `refit_full`. However we recommend spending most of your time on feature-engineering and just specify presets = `'best_quality'` inside the call to `fit()`."
      ],
      "metadata": {
        "id": "2wY7mOiWXKtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Troubleshooting:**\n",
        "\n",
        "\n",
        "*   Check that you have the right user-permissions on your computer to access the data files downloaded from Kaggle.\n",
        "*   For issues downloading Kaggle data or submitting predictions, check your Kaggle account setup and the Kaggle FAQ.\n",
        "\n"
      ],
      "metadata": {
        "id": "iwl7DIu9ZDTY"
      }
    }
  ]
}